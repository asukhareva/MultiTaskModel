{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVjPZnvelTzf",
        "outputId": "3c9e9bcd-bdff-4715-9255-80bb6846236c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "X = np.load( 'gdrive/My Drive/Colab Notebooks/data_E/X.npy')\n",
        "Y1 = np.load( 'gdrive/My Drive/Colab Notebooks/data_E/Y1.npy')\n",
        "Y2 = np.load( 'gdrive/My Drive/Colab Notebooks/data_E/Y2.npy')\n",
        "\n"
      ],
      "metadata": {
        "id": "4Kr7-JUHmYiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train1, y_test1 = train_test_split(X, Y1, test_size=0.3, random_state=10)"
      ],
      "metadata": {
        "id": "pWysLxjlmqb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train2, y_test2 = train_test_split(X, Y2, test_size=0.3, random_state=10)\n"
      ],
      "metadata": {
        "id": "QHQmfFgvnGsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class MultiTaskLoss(nn.Module):\n",
        "    def __init__(self, tasks):\n",
        "        super(MultiTaskLoss, self).__init__()\n",
        "        self.tasks = nn.ModuleList(tasks)\n",
        "        self.sigma = nn.Parameter(torch.ones(len(tasks)))\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x, targets):\n",
        "       l = [self.mse(f(x), y) for y, f in zip(targets, self.tasks)]\n",
        "       l = 0.5 * torch.Tensor(l) / self.sigma**2\n",
        "       l = l.sum() + torch.log(self.sigma.prod())\n",
        "       return l\n",
        "\n",
        "f1 = nn.Linear(5, 1, bias=False)\n",
        "f2 = nn.Linear(5, 1, bias=False)\n",
        "\n",
        "x = torch.randn(3, 5)\n",
        "y1 = torch.randn(3)\n",
        "y2 = torch.randn(3)\n",
        "\n",
        "mtl = MultiTaskLoss([f1, f2])\n",
        "\n",
        "print(list(mtl.parameters()))\n",
        "\n",
        "optimizer = optim.SGD(mtl.parameters(), lr = 0.1)\n",
        "optimizer.zero_grad()\n",
        "mtl(x, [y1, y2]).backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgK2ot4tnVeH",
        "outputId": "b5aa4d98-f3d1-49ba-8612-7938ab839f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([1., 1.], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0645, -0.3085, -0.0308,  0.0225, -0.3781]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.2141, -0.4155,  0.1545,  0.1861,  0.0534]], requires_grad=True)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(mtl.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvmrTrZOquqd",
        "outputId": "6db326be-a83a-4dd1-8df7-66e1771b3f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([1.1045, 1.0574], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0645, -0.3085, -0.0308,  0.0225, -0.3781]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.2141, -0.4155,  0.1545,  0.1861,  0.0534]], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "mtl(x, [y1, y2]).backward()\n",
        "optimizer.step()\n",
        "print(list(mtl.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrUw2ox9Xz_E",
        "outputId": "84a82629-92d1-4ad4-f31b-7c0b87ee46dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([1.2896, 1.1774], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0645, -0.3085, -0.0308,  0.0225, -0.3781]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.2141, -0.4155,  0.1545,  0.1861,  0.0534]], requires_grad=True)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class MultiTaskLoss(nn.Module):\n",
        "    def __init__(self, model, loss_fn, eta):\n",
        "        super(MultiTaskLoss, self).__init__()\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.eta = nn.Parameter(torch.Tensor(eta))\n",
        "\n",
        "    def forward(self, input, targets):\n",
        "        outputs = self.model(input)\n",
        "        print(\"ppp\", outputs[1], targets[1],\"kkk\")\n",
        "\n",
        "        loss = [l(o,y) for l, o, y in zip(self.loss_fn, outputs, targets)]\n",
        "        total_loss = torch.Tensor(loss) * torch.exp(-self.eta) + self.eta\n",
        "        return loss, total_loss.sum() # omit 1/2\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        self.e  = nn.Linear(5, 5, bias=False)\n",
        "        self.f1 = nn.Linear(5, 2, bias=False)\n",
        "        self.f2 = nn.Linear(5, 3, bias=False)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.e(input)\n",
        "        outputs = [self.f1(x), self.f2(x)]\n",
        "        return outputs\n",
        "\n",
        "## For the normal distribution,\n",
        "loss_fn1 = nn.MSELoss()\n",
        "## For the Laplace distribution,\n",
        "# loss_fn1 = nn.L1Loss()\n",
        "##\n",
        "## Note the original work uses the L1 loss for Instance Segmentation\n",
        "## and Depth Regression, as described at page 6.\n",
        "## https://arxiv.org/abs/1705.07115\n",
        "##\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "def loss_fn2(x, cls):\n",
        "    return 2 * cel(x, cls)\n",
        "\n",
        "mtl = MultiTaskLoss(model=MultiTaskModel(),\n",
        "                    loss_fn=[loss_fn1, loss_fn2],\n",
        "                    eta=[2.0, 1.0])\n",
        "\n",
        "print(list(mtl.parameters()))\n",
        "\n",
        "x = torch.randn(3,5)\n",
        "y1 = torch.randn(3, 2)\n",
        "y2 = torch.LongTensor([0, 2, 1])\n",
        "\n",
        "optimizer = optim.SGD(mtl.parameters(), lr=0.1)\n",
        "optimizer.zero_grad()\n",
        "loss, total_loss = mtl(x, [y1, y2])\n",
        "print(loss, total_loss)\n",
        "total_loss.backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "my6jaN0mrmXs",
        "outputId": "e3dd44d3-43d6-4441-c2ca-f2800890e05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([2., 1.], requires_grad=True), Parameter containing:\n",
            "tensor([[-2.8784e-01, -6.9775e-02, -1.1250e-01, -3.5962e-01, -7.9500e-02],\n",
            "        [-2.6096e-01,  1.5046e-01, -7.1984e-02, -1.3936e-01,  2.6928e-01],\n",
            "        [-4.2288e-01,  1.7780e-01,  2.9235e-02,  3.6819e-01,  2.3035e-01],\n",
            "        [ 9.0565e-02,  3.0443e-01, -3.6462e-01, -3.7437e-01,  4.2242e-01],\n",
            "        [-9.6851e-02, -1.2710e-01, -6.3388e-05,  3.7744e-02,  8.9207e-02]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.4296,  0.2982,  0.0220,  0.0688,  0.3683],\n",
            "        [ 0.2635,  0.0044,  0.1972,  0.4462,  0.3725]], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.2944, -0.0924,  0.3855,  0.2190, -0.2501],\n",
            "        [-0.0858,  0.4134,  0.4399,  0.3186,  0.1329],\n",
            "        [ 0.2883, -0.2810, -0.2576, -0.2514, -0.3879]], requires_grad=True)]\n",
            "ppp tensor([-0.0089,  0.0015,  0.0310], grad_fn=<SqueezeBackward3>) tensor([0, 2, 1]) kkk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([3, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6c0996aa5429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-6c0996aa5429>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, targets)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kkk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# omit 1/2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-6c0996aa5429>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kkk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# omit 1/2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-6c0996aa5429>\u001b[0m in \u001b[0;36mloss_fn2\u001b[0;34m(x, cls)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mcel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m mtl = MultiTaskLoss(model=MultiTaskModel(),\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(mtl.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey7NyAkwrmZ7",
        "outputId": "f6ce315f-395a-4108-d4c0-3dd41905af05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([1.9124, 0.9825], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.1035, -0.0860, -0.2420,  0.3506, -0.4184],\n",
            "        [ 0.0379,  0.0590, -0.3528,  0.1767, -0.0258],\n",
            "        [ 0.0195,  0.0472, -0.0838, -0.2745,  0.3766],\n",
            "        [ 0.3776,  0.1842, -0.1624, -0.1965,  0.0585],\n",
            "        [ 0.1905,  0.3351,  0.3259,  0.0418,  0.3488]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1931,  0.2829, -0.0435,  0.3936,  0.1867],\n",
            "        [-0.0602, -0.3225, -0.4322,  0.1304, -0.2328]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.3826, -0.0905, -0.3647,  0.2619, -0.3270],\n",
            "        [ 0.3688, -0.4137,  0.2477,  0.0929, -0.0612],\n",
            "        [-0.1673,  0.2014,  0.4349,  0.1554, -0.0880]], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss, total_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtpBJH9crmeC",
        "outputId": "ad33b8c2-db5d-4bf3-ed5e-6a35c3c70b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor(0.9183, grad_fn=<MseLossBackward0>), tensor(2.2429, grad_fn=<MulBackward0>)] tensor(3.9494, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "loss, total_loss = mtl(x, [y1, y2])\n",
        "print(loss, total_loss)\n",
        "total_loss.backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQK50YNUrmgZ",
        "outputId": "a3631be5-5102-4dcf-9640-602e1d2c731f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor(0.9183, grad_fn=<MseLossBackward0>), tensor(2.2429, grad_fn=<MulBackward0>)] tensor(3.8703, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "loss, total_loss = mtl(x, [y1, y2])\n",
        "print(loss, total_loss)\n",
        "total_loss.backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oErdXAJrmkC",
        "outputId": "b9c61b79-e7f3-45f6-8c9c-ed352f892212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor(0.9183, grad_fn=<MseLossBackward0>), tensor(2.2429, grad_fn=<MulBackward0>)] tensor(2.8748, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(mtl.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4epS0pmEVS_G",
        "outputId": "4465bfac-463c-441f-e1c6-2b15d3b638f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([0.4764, 0.8286], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.1035, -0.0860, -0.2420,  0.3506, -0.4184],\n",
            "        [ 0.0379,  0.0590, -0.3528,  0.1767, -0.0258],\n",
            "        [ 0.0195,  0.0472, -0.0838, -0.2745,  0.3766],\n",
            "        [ 0.3776,  0.1842, -0.1624, -0.1965,  0.0585],\n",
            "        [ 0.1905,  0.3351,  0.3259,  0.0418,  0.3488]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1931,  0.2829, -0.0435,  0.3936,  0.1867],\n",
            "        [-0.0602, -0.3225, -0.4322,  0.1304, -0.2328]], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.3826, -0.0905, -0.3647,  0.2619, -0.3270],\n",
            "        [ 0.3688, -0.4137,  0.2477,  0.0929, -0.0612],\n",
            "        [-0.1673,  0.2014,  0.4349,  0.1554, -0.0880]], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OP5bKdYGXWfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}